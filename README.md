# âš¡ BizForge â€” GenAI-Powered Branding Suite

> Powered by **IBM Granite** Â· **Groq LLaMA-3.3-70B** Â· **Stable Diffusion XL**

---

## ğŸ“ Project Structure

```
BizForgeGenAI/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py            â† FastAPI app (all routes)
â”‚   â”œâ”€â”€ ai_services.py     â† All AI model integrations
â”‚   â”œâ”€â”€ models.py          â† Pydantic request schemas
â”‚   â”œâ”€â”€ requirements.txt   â† Python dependencies
â”‚   â””â”€â”€ .env               â† API keys (edit this!)
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html         â† Landing page
â”‚   â”œâ”€â”€ branding.html      â† All branding tools (tabs)
â”‚   â””â”€â”€ static/
â”‚       â”œâ”€â”€ style.css
â”‚       â””â”€â”€ generated_logos/   â† Auto-created on run
â”œâ”€â”€ setup.sh               â† Linux/Mac setup script
â”œâ”€â”€ setup.bat              â† Windows setup script
â””â”€â”€ README.md
```

---

## ğŸš€ Quick Start

### Step 1 â€” Get API Keys

| Service | URL | What it's used for |
|---------|-----|-------------------|
| **Groq Cloud** | https://console.groq.com | LLaMA-3.3-70B text generation |
| **Hugging Face** | https://huggingface.co/settings/tokens | IBM Granite model + SDXL images |

### Step 2 â€” Configure .env

Edit `backend/.env`:
```
GROQ_API_KEY="gsk_xxxxxxxxxxxxxxxxxxxxxxxxxxxx"
GROQ_MODEL="llama-3.3-70b-versatile"
HF_API_KEY="hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxx"
IBM_MODEL="ibm-granite/granite-4.0-h-350m"
```

### Step 3 â€” Install & Run

**Windows:**
```cmd
cd backend
python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt
python main.py
```

**Linux / Mac:**
```bash
cd backend
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
python main.py
```

### Step 4 â€” Open in Browser

```
http://localhost:8000
```

---

## ğŸ› ï¸ Features

| Feature | Endpoint | AI Model |
|---------|----------|----------|
| Brand Name Generator | POST /api/generate-brand | Groq LLaMA |
| Logo Prompt + Image | POST /api/generate-logo | Groq + SDXL |
| Marketing Content | POST /api/generate-content | Groq LLaMA |
| Design System / Colors | POST /api/get-colors | Groq LLaMA |
| Sentiment Analysis | POST /api/analyze-sentiment | Groq LLaMA |
| AI Branding Chat | POST /api/chat | IBM Granite (fallback: Groq) |
| Voice Transcription | POST /api/transcribe-voice | Google Speech-to-Text |

---

## âš ï¸ Notes

- **IBM Granite** loads locally â€” this requires ~2GB RAM and takes 30-60s on first start.  
  If it fails to load, the chat falls back to Groq automatically â€” everything still works.
- **SDXL image generation** requires a valid `HF_API_KEY`. Without it, logo prompts still  
  generate (text only) â€” the image step is skipped gracefully.
- **Voice input** uses browser's Web Speech API (Chrome/Edge recommended) on the frontend,  
  with a server-side Google Speech Recognition fallback via file upload.

---

## ğŸ”§ Troubleshooting

| Problem | Fix |
|---------|-----|
| `Groq API error` | Check GROQ_API_KEY in .env |
| `Granite load failed` | Normal on low RAM â€” chat uses Groq fallback |
| `SDXL 503 error` | HF model is loading â€” retry in 20s |
| `CORS error` | Make sure you access via `http://localhost:8000` |
| `Module not found` | Run `pip install -r requirements.txt` inside venv |
